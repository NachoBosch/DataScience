2+2
1
2
3
4
5
6
1000!
10*100000
3*5
#Primer clase de Programacion I#
#Comentario con numeral
3*5
3*10
#Primer clase de Programacion I#
#Comentario con numeral
3*5
3*10
#Primer clase de Programacion I#
#Comentario con numeral
3*5
numero<-24
vector<-c(2,5,7,9)
vector_2<-c("Ana P.","Lucas J.")
vector_2<-c("Ana P.","Lucas J.")
vector
vector_2
vector
vector_2
vector*10
vector[3]*2
vector[3]
vector_2[3]
vector_2[3]
vector<-c(2,5,7,9)
vector_2<-c("Ana P.","Lucas J.")
vector_2[3]
vector[3]
clas(vector[3])
class(vector[3])
class(vector_2)
class(vector_2[1])
vec
vec <- seq(from=1,to=100,by=2)
vec
length(vec)
names(familia)
milista <-list(numeros=1:5,
ciudades=c("Buenos Aires",
"Neuquen"))
familia <- list(padre="Juan",
madre="Maria",
numero.hijos=2,
nombre.hijos=c("Luis","Carlos"),
edades.hijos=c(7,5),
ciudad="La Plata")
names(familia)
path <-getwd()
print(path)
setwd(path)
# siempre comienza la sesion limpiando los paneles
rm(list=ls())# Borrar los datos de entorno cargados en memoria
install.packages("tidyverse")
library(tidyverse)
tidyverse_packages()
mi_csv<-read.table("mydata.csv",header=True,dec=".")
print(head(mi_csv))
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("mydata.csv",header=TRUE,dec=".")
setwd(path)
path <-getwd()
setwd(path)
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("mydata.csv",header=TRUE,dec=".")
setwd(getwd())
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("mydata.csv",header=TRUE,dec=".")
path = getwd()
print(path)
setwd(path)
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("mydata.csv",header=TRUE,dec=".")
setwd("C:/Users/Nacho/Documents")
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("mydata.csv",header=TRUE,dec=".")
print(head(mi_csv))
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("C:\Code\DataScience\Data Science - Curso\R\Clase 4\mydata.csv",header=TRUE,dec=".")
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("C:\Code\DataScience\Data Science - Curso\R\Clase 4\mydata.csv",header=TRUE,dec=".")
#Importación de datos ----
#read.table()
#read.csv()
#read.csv2()
mi_csv<-read.table("C:/Code/DataScience/Data Science - Curso/R/Clase 4/mydata.csv",header=TRUE,dec=".")
print(head(mi_csv))
View(mi_csv)
library(readxl)
#read_excel()
#read_xls()
#read_xlxs()
mi_excel <- read_excel("C:/Code/DataScience/Data Science - Curso/R/Clase 4/mydata.xlsx",col_names=TRUE)
print("Excel",head(mi_excel))
#install.packages("readxl")
library(readxl)
#read_excel()
#read_xls()
#read_xlxs()
mi_excel <- read_excel("C:/Code/DataScience/Data Science - Curso/R/Clase 4/mydata.xlsx",col_names=TRUE)
print("Excel",head(mi_excel))
#read_excel()
#read_xls()
#read_xlxs()
mi_excel <- read_excel("C:/Code/DataScience/Data Science - Curso/R/Clase 4/mydata.xlsx",col_names=TRUE)
print(head(mi_excel))
names(mi_excel)
#write.table(mi_csv,file="mi_csv.csv",row.names=False,sep=',')
str(mi_excel)
library(dplyr)
library(GGally)
library(lmtest)
library(car)
# Usamos el dataset mtcars ya incluido en R
datos <- mtcars
str(datos)
# Nombre de las columnas
names(datos)
# Eliminamos variables que no son útiles para el ejercicio (que no son contínuas)
datos <- select(datos, -c(am, vs, cyl, gear, carb))
str(datos)
ggpairs(datos, lower = list(continuous = "smooth"),
diag = list(continuous = "bar"), axisLabels = "none")
plot(mtcars$mpg,mtcars$wt)
plot(mtcars$qsec,mtcars$hp)
plot(mtcars$mpg,mtcars$hp)
plot(mtcars$hp,mtcars$qsec)
cor(datos$mpg,datos$wt)
cor(mtcars$qsec,mtcars$hp)
cor(mtcars$mpg,mtcars$hp)
cor(mtcars$hp,mtcars$qsec)
cor.test(datos$mpg,datos$wt)
cor.test(mtcars$qsec,mtcars$hp)
cor.test(mtcars$mpg,mtcars$hp)
cor.test(mtcars$hp,mtcars$qsec,method='pearson')
#Correlacion = 0--> H0=0 p<0.05 --> H1 si hay correlacion
# -1 (cor inversa) 0(no hay) +1(cor directa)
#asumiendo que ambos datos tienen dist normal
cor.test(mtcars$mpg,mtcars$hp,method = 'spearman')
cor.test(mtcars$mpg,mtcars$hp,method = 'kendall')
shapiro.test(datos$mpg)
shapiro.test(datos$wt)
shapiro.test(mtcars$qsec)
shapiro.test(mtcars$hp)
shapiro.test(mtcars$mpg)
shapiro.test(mtcars$hp)
shapiro.test(mtcars$hp)#p<0.05 no es normal
shapiro.test(mtcars$qsec)# p>0.05 si es normal
modelolineal = lm(hp~qsec, data =datos)# hp explica 50% del qsec
summary(modelolineal)
qqnorm(modelolineal$residuals)
qqline(modelolineal$residuals)
# Los residuos se aproximan a la linealidad esperada
mean(modelolineal$residuals)
# 2) Dist NormaNo podemos rechazar la hipótesis nula,
# hay evidencia de dist normal
shapiro.test(modelolineal$residuals)
# 3) que la varianza sea constante (homocedasticidad)
bptest(modelolineal)
# 4) Autocorrelación
dwt(modelolineal, alternative = "two.sided")
nuevos = data.frame ( wt = c(2.5, 2.9))
predict(modelolineal, nuevos)
modelolineal = lm(hp~qsec, data =datos)# hp explica 50% del qsec
summary(modelolineal)
qqnorm(modelolineal$residuals)
qqline(modelolineal$residuals)
plot(modelolineal$residuals, modelolineal$fitted.values, main="Res vs Pred",
xlab="Residuos ", ylab="Valor predicho ", pch=19)
# 2) Dist NormaNo podemos rechazar la hipótesis nula,
# hay evidencia de dist normal
shapiro.test(modelolineal$residuals)
nuevos = data.frame ( wt = c(2.5, 2.9))
predict(modelolineal, nuevos)
modelolineal = lm(hp~qsec, data =datos)
summary(modelolineal)
nuevos = data.frame ( wt = c(2.5, 2.9))
predict(modelolineal, nuevos)
plot(mtcars$qsec,mtcars$hp)
mtcars?
hp~
mtcars
mtcars
modelolineal = lm(hp~qsec, data =datos)
summary(modelolineal)
nuevos = data.frame ( wt = c(180, 205))
predict(modelolineal, nuevos)
nuevos = data.frame ( wt = c(180))
predict(modelolineal, nuevos)
cars <- read.csv("https://raw.githubusercontent.com/amankharwal/Website-data/master/CarPrice.csv")
cars.head(3)
head(cars,n_lines=3)
head(cars)
View(cars)
c <- select(cars,c(wheelbase,carlength,carwidth,carheight,curbweight,enginesize,boreratio,stroke,compressionratio,horsepower,peakrpm,citympg,highwaympg,price))
c
str(c)
sum(is.na(c))
ggpairs(c, lower = list(continuous = "smooth"),
diag = list(continuous = "bar"), axisLabels = "none")
# Price = fn(HorsePower)
plot(c$horsepower,c$price)
cor(c$horsepower,c$price)
shapiro.test(c$horsepower)
shapiro.test(c$price)
a <- ggplot(c)
a+geom_histogram(aes(price))
a+geom_histogram(aes(horsepower))
cor.test?
cor.test()
cor.test()?
cor.test(c$horsepower,c$price,method="pearson")
cor.test(c$horsepower,c$price,method="pearson")
cor.test(c$horsepower,c$price,method="spearman")
modelolineal = lm(price~horsepower, data = c)
summary(modelolineal)
qqnorm(modelolineal$residuals)
qqline(modelolineal$residuals)
plot(modelolineal$residuals, modelolineal$fitted.values, main="Res vs Pred",
xlab="Residuos ", ylab="Valor predicho ", pch=19)
# Los residuos se aproximan a la linealidad esperada
mean(modelolineal$residuals)
# La media es muy cercana a 0
# 2) Dist NormaNo podemos rechazar la hipótesis nula,
# hay evidencia de dist normal
shapiro.test(modelolineal$residuals)
# 3) que la varianza sea constante (homocedasticidad)
bptest(modelolineal)
# el test de Bausch Pagan nos dicen que no tenemos evidencia para
# para sostener que la varianza no es homogenea
# 4) Autocorrelación
dwt(modelolineal, alternative = "two.sided")#Durbin Watson
# rechazamos H0, no hay autocorrelación entre los residuos.
# esto significa que no hay valor de residuo que condiciones a los residuos cercanos.
nuevos = data.frame(horsepower = c(205))
predict(modelolineal, nuevos)
plot(mtcars$mpg,mtcars$wt)
grafico1 = ggplot(mtcars,aes(mpg,wt))
grafico1 = ggplot(c,aes(price,horsepower))
grafico1 = ggplot(c,aes(price,horsepower))
grafico1 + geom_point()+geom_smooth(method="lm",colour="red")
## MODEL REGRESION LINEAL MULTIPLE ##
modelolineal = lm(price~wheelbase+carlength+carwidth+carheight+curbweight+enginesize+boreratio+stroke+compressionratio+horsepower+peakrpm+citympg+highwaympg, data = c)
summary(modelolineal)
#Extraemos variables de más
modelolineal = lm(price~carlength+carwidth+enginesize+stroke+compressionratio+horsepower+peakrpm+citympg, data = c)
summary(modelolineal)
#Extraemos variables de más
modelolineal = lm(price~carwidth+enginesize+stroke+compressionratio+horsepower+peakrpm, data = c)
summary(modelolineal)
#Extraemos variables de más
modelolineal = lm(price~carwidth+enginesize+stroke+compressionratio+peakrpm, data = c)
summary(modelolineal)
#Extraemos variables de más
modelolineal = lm(price~carwidth+enginesize+stroke+peakrpm, data = c)
summary(modelolineal)
qqnorm(modelolineal$residuals)
qqline(modelolineal$residuals)
plot(modelolineal$residuals, modelolineal$fitted.values, main="Res vs Pred",
xlab="Residuos ", ylab="Valor predicho ", pch=19)
# Los residuos se aproximan a la linealidad esperada
mean(modelolineal$residuals)
# La media es muy cercana a 0
# 2) Dist NormaNo podemos rechazar la hipótesis nula,
# hay evidencia de dist normal
shapiro.test(modelolineal$residuals)
# 3) que la varianza sea constante (homocedasticidad)
bptest(modelolineal)
# el test de Bausch Pagan nos dicen que no tenemos evidencia para
# para sostener que la varianza no es homogenea
# 4) Autocorrelación
dwt(modelolineal, alternative = "two.sided")#Durbin Watson
# rechazamos H0, no hay autocorrelación entre los residuos.
# esto significa que no hay valor de residuo que condiciones a los residuos cercanos.
grafico2 = ggplot(c,aes(price,carwidth,enginesize,stroke,peakrpm))
grafico2 + geom_point()+geom_smooth(method="lm",colour="red")
## MODEL REGRESION LINEAL SIMPLE ##
modelolineal = lm(price~horsepower, data = c)
summary(modelolineal)
# rechazamos H0, no hay autocorrelación entre los residuos.
# esto significa que no hay valor de residuo que condiciones a los residuos cercanos.
AIC(modelolineal)
BIC(modelolineal)
#Extraemos variables de más
modelolineal = lm(price~carwidth+enginesize+stroke+peakrpm, data = c)
summary(modelolineal)
## MODEL REGRESION LINEAL SIMPLE ##
modelolineal = lm(price~horsepower, data = c)
summary(modelolineal)
# rechazamos H0, no hay autocorrelación entre los residuos.
# esto significa que no hay valor de residuo que condiciones a los residuos cercanos.
AIC(modelolineal)
BIC(modelolineal)
summary(modelolineal)$adj.r.squared
#Extraemos variables de más
modelolineal = lm(price~carwidth+enginesize+stroke+peakrpm, data = c)
summary(modelolineal)
AIC(modelolineal)
BIC(modelolineal)
summary(modelolineal)$adj.r.squared
modelo.pasos <- stepAIC(modelolineal, direction = "both",
trace = TRUE)
summary(modelo.pasos)
library(mlbench)
library(MASS)
library(dplyr)
library(GGally)
library(lmtest)
library(car)
modelo.pasos <- stepAIC(modelolineal, direction = "both",
trace = TRUE)
summary(modelo.pasos)
#####################################
## MODEL REGRESION LINEAL MULTIPLE ##
#####################################
modelotutti = lm(price~wheelbase+carlength+carwidth+carheight+curbweight+enginesize+boreratio+stroke+compressionratio+horsepower+peakrpm+citympg+highwaympg, data = c)
summary(modelotutti)
modelo.pasos <- stepAIC(modelotutti, direction = "both",trace = TRUE)
summary(modelo.pasos)
####################################################
################## Cars Price ######################
####################################################
pc <- read.csv('https://raw.githubusercontent.com/amankharwal/Website-data/master/CarPrice.csv')
str(pc)
library(mlbench)
library(MASS)
library(dplyr)
library(GGally)
library(lmtest)
library(car)
pcars <- select(pc,-c(fuelsystem,cylindernumber,enginetype,enginelocation,drivewheel,carbody,
doornumber,aspiration,fueltype,CarName))
ggpairs(pcars, lower = list(continuous = "smooth"),
diag = list(continuous = "bar"), axisLabels = "none")
cor.test(pcars$citympg,pcars$highwaympg)
cor.test(pcars$citympg,pcars$highwaympg,method = 'Person')
shapiro.test(pcars$citympg)
shapiro.test(pcars$highwaympg)
plot(pcars$citympg)
a <- ggplot(pcars)
a+geom_histogram(aes(pcars$citympg))
shapiro.test(pcars$enginesize)
library(mlbench)
library(MASS)
library(dplyr)
library(GGally)
library(lmtest)
######################
###### Hackaton ######
#####################
#Setear path hacia 'C:\Code\DataScience\Data Science - Curso\Hackaton'
setwd('C:/Code/DataScience/Data Science - Curso/Hackaton')
#Cargamos dataset
df <- read.csv('water_potability.csv')
#Visualizamos los 3 primeros filas
head(df,3)
#Rellenamos los nan
sum(is.na(df))
is.na(df)
str(df)
names(df)
#Limpiamos nan de las columnas ph, Sulfate, Trihalomethanes
ph_mean <- mean(df$ph,na.rm = TRUE)
df$ph[is.na(df$ph)] <- ph_mean
sum(is.na(df$ph))
is.na(df).sum()
sum(is.na(df$Sulfate))
sulfate_mean <- mean(df$Sulfate)
#Visualizamos los 3 primeros filas
head(df,3)?
#Rellenamos los nan
sum(is.na(df))
head(?)
head?
#Rellenamos los nan
sum(is.na(df))
df$Sulfate[is.na(df$Sulfate)] <- suldate_mean
sulfate_mean <- mean(df$Sulfate)
df$Sulfate[is.na(df$Sulfate)] <- suldate_mean
df$Sulfate[is.na(df$Sulfate)] <- sulfate_mean
sum(is.na(df$Sulfate))
sulfate_mean <- mean(df$Sulfate)
df$Sulfate[is.na(df$Sulfate)] <- sulfate_mean
sum(is.na(df$Sulfate))
sulfate_mean <- mean(df$Sulfate, na.rm=True)
sulfate_mean <- mean(df$Sulfate, na.rm=TRUE)
df$Sulfate[is.na(df$Sulfate)] <- sulfate_mean
sum(is.na(df$Sulfate))
summary(df)
info(df)
sum(is.na(df$Trihalomethanes))
trihalo_mean <- mean(df$Trihalomethanes,na.rm = TRUE)
df$Trihalomethanes[is.na(df$Trihalomethanes)] <- trihalo_mean
sum(is.na(df$Trihalomethanes))
#Analizamos correlacion entre las variables numericas dejando de lado la potability
data_num <- select(df, -c(Potability))
data_num
ggpairs(data_num, lower = list(continuous = "smooth"),
diag = list(continuous = "bar"), axisLabels = "none")
ggpairs(df, lower = list(continuous = "smooth"),
diag = list(continuous = "bar"), axisLabels = "none")
#Analizamos normalidad de cada variable
shapiro.test(df$ph)
shapiro.test(?)
shapiro.test?
sxsa
#Analizamos normalidad de cada variable
shapiro.test(df$ph)
shapiro.test(df$Hardness)
shapiro.test(df$Solids)
shapiro.test(df$Chloramines)
shapiro.test(df$Sulfate)
shapiro.test(df$Conductivity)
shapiro.test(df$Organic_carbon) #Se rechaza la Ho por lo que la muestra no se distribuyen de modo normal
shapiro.test(df$Trihalomethanes)
shapiro.test(df$Turbidity) #Se rechaza la Ho por lo que la muestra no se distribuyen de modo normal
shapiro.test(df$Potability)
#Test de correlacion
cor.test(df$Potability,df$ph,method='kendall')
#Test de correlacion
cor.test(df$Potability,df$ph,method='pearson')
cor.test(df$Potability,df$Hardness,method='kendall')
cor.test(df$Potability,df$Solids,method='kendall')
source("C:/Code/DataScience/Data Science - Curso/Hackaton/water_potability.R")
cor.test(df$Potability,df$Chloramines,method='kendall')
cor.test(df$Potability,df$Sulfate,method='kendall')
cor.test(df$Potability,df$Conductivity,method='kendall')
cor.test(df$Potability,df$Organic_carbon,method='kendall')
cor.test(df$Potability,df$Trihalomethanes,method='kendall')
cor.test(df$Potability,df$Turbidity,method='kendall')
#Plots
plot(df$Potability,df$Solids)
plot(df$Potability,df$Chloramines)
plot(df$Potability,df$Sulfate)
plot(df$Potability,df$Conductivity)
plot(df$Potability,df$Organic_carbon)
plot(df$Potability,df$Trihalomethanes)
plot(df$Potability,df$Turbidity)
#Plots
plot(df$Potability,df$Solids)
plot(df$Potability,df$Chloramines)
plot(df$Potability,df$Sulfate)
plot(df$Potability,df$Conductivity)
plot(df$Potability,df$Organic_carbon)
plot(df$Potability,df$Trihalomethanes)
plot(df$Potability,df$Turbidity)
ggpairs(df, lower = list(continuous = "smooth"),
diag = list(continuous = "bar"), axisLabels = "none")
